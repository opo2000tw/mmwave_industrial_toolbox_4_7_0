<!DOCTYPE html><html><head>
  <meta charset="UTF-8">
  <title>Detecting Human Falls and Stance with IWR6843ODS</title>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="../.metadata/.html/scripts/toolbox.js"></script>
  <script src="../.metadata/.html/scripts/toolbox_fixes.js"></script>
  <link rel="stylesheet" href="../.metadata/.html/styles/link.css">
  <link rel="stylesheet" href="../.metadata/.html/scripts/strapdown/v/0.2/fonts/ubuntu-regular-woff.css">
  <link rel="stylesheet" href="../.metadata/.html/scripts/strapdown/v/0.2/fonts/glyphicons-halflings-regular.css">
  <link rel="stylesheet" href="../.metadata/.html/scripts/strapdown/v/0.2/themes/united2.min.css">
  <link rel="stylesheet" href="../.metadata/.html/scripts/strapdown/v/0.2/themes/bootstrap-responsive.min.css">

  <style>
    .img-responsive {
      max-height: 300px;
    }

    .btn-primary {
      margin: 5px;
    }
  </style>
</head>

<body style="">
  <div class="container">
    <nav class="navbar navbar-default navbar-static-top">
      <div class="container-fluid">
        <div class="navbar-header">
          <div id="headline" class="navbar-brand">Detecting Human Falls and Stance with IWR6843ODS</div>
        </div>
      </div>
    </nav>
    <div class="container">
      <div class="row row-offcanvas row-offcanvas-left">
        <div class="col-xs-12 col-sm-9" id="content"><p><strong>Introduction</strong></p><p>The objective of this experiment is to evaluate the ability of TI mmWave Sensor to detect the height and stance of People when the sensor is mounted on the wall or ceiling.</p><p>In many circumstances, it can be valuable to detect the stance of a person with mmWave sensors.  For example, in an elderly care scenario, the mmWave sensor can detect the stance, as well as detect dangerous events like falls, without compromising the privacy of the individual. The sensor delivers 4D point cloud data - position in X, Y, Z, and velocity.  While the point cloud gives information about the location and size of the person, it is not precise enough to be used to determine the identity or take an image of the person.  The goal of this experiment is to determine how this information can be used to detect falls and determine the stance of the person being monitored.  We will show the point cloud captured with the sensor at different heights, to determine if a mounting agnostic algorithm could be developed to determine stance and detect falls. Finally, we will discuss a potential implementation of the stance detection algorithm.</p><p><strong>Setup </strong></p><p>The following software and hardware setup was used to complete the experiment:</p><p><strong>Hardware Setup:</strong></p><ol><li>This experiment was conducted inside a room, roughly 3m x 6m.</li><li>A IWR6843ISK-ODS was mounted to an Industrial Carrier Board (MMWAVEICBOOST).  This setup will be referred to as ODS.<ol><li>The ODS antenna provides equal Angle Resolution in Azimuth and Elevation.  This will create a balanced image of the person in the scene, which can provide better information about the person's dimensions. </li><li>The ODS antenna has better angular accuracy along the Elevation plane than the ISK antenna.  This will allow the ODS to more accurately determine the height of a person in the scene.</li></ol></li><li>The ODS was mounted on top of a tripod at 3 different heights:<ol><li>4.5 feet</li><li>5.5 feet</li><li>6.5 feet</li></ol></li><li>The ODS was mounted with no downtilt, so that the antenna faced directly forwards.</li><li>A camera was placed behind the sensor to capture a base truth.</li></ol><p><img style="height:400;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/HardwareMount.jpg" class="img-responsive"></p><p><strong>Software Setup:</strong></p><ol><li>The ODS was flashed with the lab0025 Point Cloud Software, which can be found <a href="http://dev.ti.com/tirex/explore/node?node=APz8.I6J1HfQwW3H2CVjmA__VLyFKFf__LATEST">here</a> on TI Resource Explorer.</li><li>The <a href="http://dev.ti.com/tirex/explore/node?node=AA6rXg12eWP3spxiTycerQ__VLyFKFf__LATEST">Zone Occupancy Detection Visualizer</a> was used to show the point cloud.<ol><li>The X axis was set to show points from -2 to 2</li><li>The Z axis was set to show a 2.5 meter range.  The ends of the range were set based on the height of the device.</li><li>The GUI was rotated so that the GUI had the same view point as the camera, which was directly behind the EVM.</li></ol></li><li>The attached sensor configuration was used: <span><a href="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/profile_iwr6843_ods_3d.cfg" class="btn btn-primary">profile_iwr6843_ods_3d.cfg</a></span><ol><li>This sensor configuration has a very fine range resolution: 4cm.  This limits maximum range to 8 meters. It also has a fine velocity resolution of 0.1 m/s. </li><li>This configuration was chosen as it would provide the most detection points for a person in the scene. The point cloud uses Range-Velocity detection. Increasing the Range Resolution and velocity resolution means the subject will take up more range and velocity bins, leading to more detected points.</li></ol></li></ol><h1 id="-procedure-"><strong>Procedure</strong></h1><p>For each mounting height, the following steps were followed:</p><ol><li>Point Cloud demo is configured and begins running</li><li>One Person enters the scene moves in front of the sensor<ol><li>The person walks a small circle between 2 and 5 meters.</li></ol></li><li>The person stands about 2 meters in front of the sensor and takes a variety of poses:<ol><li>Standing</li><li>Sitting</li><li>Laying</li><li>Falling - stands, then falls down to a laying position</li></ol></li><li>This is repeated at 5 meters<br><br></li></ol><p>During the course of the experiment, the Point Cloud software was left running.</p><h1 id="-observations--"><strong>Observations:</strong></h1><p><strong><br></strong>GUI output will look like the following:</p><p><img style="height:400;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/AnnotatedPhoto.PNG" class="img-responsive"></p><p>From the captured footage, we can see the following:</p><ol><li>When a person is walking, we can see a long, thin cluster in the point cloud which moves through the scene.  The reported height of the point cloud is dependent on the height of the sensor.<ol><li>At the bottom of the cluster, you can see variation in width due to the legs moving<br><ac:structured-macro ac:name="view-file" ac:schema-version="1" ac:macro-id="6259bdb2-a5ab-42db-bf11-205a91ecd5c3"><ac:parameter ac:name="name"><attachment ri:filename="Walking6p5ft.mp4"></attachment></ac:parameter><ac:parameter ac:name="height">250</ac:parameter></ac:structured-macro></li></ol></li><li><p>We can see differences in the point cloud based on the stance of the person.</p><table class="table table-striped table-bordered"><tbody><tr><th colspan="1">Distance Meters</th><th>Standing</th><th>Sitting</th><th>Laying</th></tr><tr><td colspan="1">2</td><td><img style="height:400;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/Standing4p52m.PNG" class="img-responsive"><div class="content-wrapper"><p><br></p></div></td><td><div class="content-wrapper"><p><img style="height:400;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/Sitting4p52m.PNG" class="img-responsive"></p></div></td><td><div class="content-wrapper"><p><img style="height:400;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/Laying4p52m.png" class="img-responsive"></p></div></td></tr><tr><td colspan="1">5</td><td><div class="content-wrapper"><p><img style="height:400;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/Stand5m.PNG" class="img-responsive"></p></div></td><td><div class="content-wrapper"><p><img style="height:400;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/Sit5m.PNG" class="img-responsive"></p></div></td><td><div class="content-wrapper"><p><img style="height:400;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/Laying4p55m.PNG" class="img-responsive"></p></div></td></tr></tbody></table><p><br></p><ol><li>When a person is standing, we see a long, thin cluster.<ol><li>When the person is very still, we can see that some points near the legs disappear, however, the height of the point cloud remains roughly the same.</li></ol></li><li>When a person sits, we see a round cluster<ol><li>Compared to a person standing, the cluster will appear relatively lower.</li></ol></li><li>When a person lays, we can see a short, wide cluster - much like the standing cluster rotated 90 degrees.<ol><li><p>Again, the height will be relatively lower than the standing or sitting clusters.</p></li></ol></li></ol></li><li>When a person sits, we can see the transition from standing to sitting - the point cloud gets shorter and wider, and it moves downward.<br><img style="height:250;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/StandSitStand5p5ft2m.gif" class="img-responsive"></li><li>When a person falls, we see the point cloud transition from a long, thin cloud, and become a short wide cloud.  In the typical case, this cloud will be much lower than the standing cloud.<br><img style="height:250;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/Fall6p5ft2m.gif" class="img-responsive"></li><li>The reported height of the point cloud is dependent on the height of the sensor.  When the sensor is mounted lower, the point cloud appears higher.  This means that a stance detection algorithm assuming an absolute height for stance detection will fail if the sensor is at the wrong height.  Similarly, a short person could fall below the height of the sensor.<ol><li><p>From left to right, the sensor is mounted at 4.5 ft, 5.5 ft, 6.5 ft.  In each scene, the point cloud looks roughly the same. However, notice that the tallest point is at a different height in each video.</p><table class="table table-striped table-bordered"><tbody><tr><th>4.5 Ft</th><th>5.5 Ft</th><th>6.5 Ft</th></tr><tr><td><div class="content-wrapper"><p><img style="height:250;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/walking4p5feet.gif" class="img-responsive"></p></div></td><td><div class="content-wrapper"><p><img style="height:250;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/Walking5pft.gif" class="img-responsive"></p></div></td><td><div class="content-wrapper"><p><img style="height:250;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/Walking6p5ft.gif" class="img-responsive"></p></div></td></tr></tbody></table></li></ol></li><li>Regardless of mounting height of the sensor, change in height when a person sits down (from standing) or falls will be consistent. <ol><li><p>From left to right, the sensor is mounted at 4.5 ft, 5.5 ft, 6.5 ft.  Despite the reported height being different, the relative change in height is roughly 0.6 meters.</p><table class="table table-striped table-bordered"><tbody><tr><th>4.5 Ft</th><th>5.5 Ft</th><th>6.5 Ft</th></tr><tr><td><div class="content-wrapper"><p><img style="height:250;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/2m4pftStandSitStand.gif" class="img-responsive"></p></div></td><td><div class="content-wrapper"><p><img style="height:250;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/StandSitStand5p5ft2m.gif" class="img-responsive"></p></div></td><td><div class="content-wrapper"><p><img style="height:250;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/Stand2Sit6p5ft2m.gif" class="img-responsive"></p></div></td></tr></tbody></table></li></ol></li></ol><h1 id="-algorithm--"><strong>Algorithm:</strong></h1><p>For a stance detection algorithm, we can make the following assumptions:</p><ol><li>In an indoor case, the ground will be flat - i.e., there will be no change in elevation</li><li>The sensor could be mounted at different heights, depending on the needs of the user<ol><li>The sensor can be mounted with no down tilt in most cases</li></ol></li><li>The tracked people could be different heights</li><li>The above point cloud observations will be roughly consistent across all tracked people.</li><li>People cannot just appear - they must enter the scene.  When they enter the scene, they will be walking or running.</li></ol><p>From the above assumptions, we can formulate the following algorithm:</p><ol><li>When a person enters the scene, assume they are standing<ol><li>Calculate and save standing height</li></ol></li><li>For each frame:<ol><li>Calculate height of each target</li><li>Calculate dimensions of each target</li><li>If (height changes across the last frames)<ol><li>If (height change > -1 m and height change < -10 cm)<ol><li>Standing to sitting</li></ol></li><li>If (height change < -1 m)<ol><li>Standing to laying</li><li>if (change happens in less than 1 second)<ol><li>fall event</li></ol></li></ol></li><li>if (height change > 10 cm and height change < 1 m, and target is laying)<ol><li>Laying to sitting</li></ol></li><li>if (height change > 1m and target is laying)<ol><li>Laying to Standing</li></ol></li><li>if (target is sitting)<ol><li>If (height change is positive)<ol><li>sitting to standing</li></ol></li><li>else<ol><li>sitting to laying</li></ol></li></ol></li></ol></li></ol></li></ol><p>The above algorithm uses height exclusively for stance detection.  There are corner cases where this could fail. For example, if a person lays on a couch, there height may be similar to that of a person sitting on a floor.  In this case, the algorithm could show sitting or laying.  The dimension of the target could be used to make a determination about stance as well. From the observation section, please note that the dimensions of a still target are usually smaller than that of a moving target.  So the dimensions should only be considered during the transition event. In the sensor mounting used in this experiment, Z dimension represents the height of the target, X and Y represent width.  Extend the stance detection algorithm example with the below:</p><ol><li>Given a stance change event:<ol><li>if (Z is much greater than X and Y)<ol><li>Target is standing  - long and thin point cloud</li></ol></li><li>if (Z, X and Y are roughly equal)<ol><li>Target is probably sitting - spherical point cloud</li></ol></li><li>if (X or Y is much greater than Z)<ol><li>target is probably laying - wide and flat point cloud</li></ol></li></ol></li></ol><p>For height calculation, use the following algorithm:</p><ol><li>Search across points associated with a tracked person for the highest point</li><li>Store the highest point's height in a circular buffer<ol><li>Set the size of the circular buffer so that it is completely repopulated every 0.5 - 1 second</li><li>Longer averages give more consistent measurement, shorter averages give more responsive measurements</li></ol></li><li>Average the points in the circular buffer</li></ol><p>For dimension calculation, use the following algorithm:</p><ol><li>For each dimension in <x, y,="" z="">:<br><ol><li>Search across points associated with the target for largest and smallest point in the dimension</li><li>dimension is largest minus smallest</li><li>store this in a circular buffer</li><li>Average across the circular buffer</li></ol></x,></li></ol><p>Alternatively, TI's gtrack software (available in the <a href="http://www.ti.com/tool/MMWAVE-SDK">mmWave SDK</a>), provides the dimensions of each tracked target.</p><h1 id="-height-detection-"><strong>Height Detection</strong></h1><p>To prove the the algorithm above, we will show a height detection example of a human target between 1 and 3 meters from the device.  In this example, the above described height detection algorithm is added to the Overhead People Counting GUI. User's wishing to replicate this will need to make the modification themselves. The circular buffer mentioned in the height detection algorithm above stores 20 values. </p><p>The persons measured height is measured at 2 points, standing and sitting.</p><table class="table table-striped table-bordered"><tbody><tr><th>Standing Height: 5.8 feet (1.8 meters)</th><th>Sitting Height: 4.6 feet (1.4 meters)</th></tr><tr><td><div class="content-wrapper"><p><img style="border:1px;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/IMG-2117.JPG" class="img-responsive"></p></div></td><td><div class="content-wrapper"><p><img style="" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/IMG-2119.JPG" class="img-responsive"></p></div></td></tr><tr><td colspan="1"><div class="content-wrapper"><p><img style="height:400;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/StandingHeightMeasureAnnotated.png" class="img-responsive"></p></div></td><td colspan="1"><div class="content-wrapper"><p><img style="height:400;" src="./images/Detecting+Human+Falls+and+Stance+with+IWR6843ODS/SittingHeightMeasure.PNG" class="img-responsive"></p></div></td></tr></tbody></table><p>From the table above, you can see that the algorithm generally can find height with 0.1 meters. Also note that when the subject sits, the height decreases by about 0.4 meters.  This is 4x greater than the measurement variation; a event marking a change in stance can accurately be identified by monitoring the relative height of the target.</p><h1 id="-conclusion-"><strong>Conclusion</strong></h1><ol><li>When a person changes stance, we can see changes in the point cloud<ol><li>Tall, thin point clouds are generally standing people</li><li>Spherical point clouds are generally sitting people</li><li>flat and wide point clouds are generally laying people</li></ol></li><li>By looking at the relative height of the target, we can use height to help determine stance regardless of the mounting height of the sensor<ol><li>This means height of the sensor does not matter for stance detection. The exception is mounting the sensor in such a way that the target falls outside the field of view.</li></ol></li><li>Using the dimensions of the target can help remove errors due to some corner cases</li><li>The algorithm outlined in this experiment can be used as a starting point for Stance or height detection applications.<ol><li>The data shows that the algorithm can be used regardless of mounting height, and does not need to know mounting height.</li><li>The data also shows that there are differences besides height between the stances a person may take that can be used to increase the reliability of stance detection.</li><li>The point cloud data does not show identifying information, so this stance detection can be used in privacy focused applications.</li></ol></li><li>Integrating height detection with a tracker can be used in applications like doors and gates to reduce energy used when opening the gate.</li><li>At 5m, we see the point cloud is sparser than at 2 m.  However, it still gave a decent representation of the person.  At a long enough range, the device may not return enough points to accurately detect stance. This may limit stance detection to indoor spaces.</li></ol><p><ac:structured-macro ac:name="view-file" ac:schema-version="1" ac:macro-id="7b0b2b43-cdbc-40e9-87c9-8fa98e07b127"><ac:parameter ac:name="name"><attachment ri:filename="HeightDetectionCut.mp4"></attachment></ac:parameter><ac:parameter ac:name="height">250</ac:parameter></ac:structured-macro></p></div>
        <div class="col-xs-4 col-sm-2 sidebar-offcanvas bs-docs-sidebar hidden-print" id="sidebar-overview"><ul class="nav nav-stacked fixed" id="sidebar"><li><a href="#-procedure-">Procedure</a></li><li><a href="#-observations--">Observations:</a></li><li><a href="#-algorithm--">Algorithm:</a></li><li><a href="#-height-detection-">Height Detection</a></li><li><a href="#-conclusion-">Conclusion</a></li></ul></div>
      </div>
    </div>
  </div>

  <script src="../.metadata/.html/scripts/strapdown/vendor/bootstrap.min.js"></script>
  <div class="modal" id="imagemodal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
    <div class="vertical-alignment-helper">
      <div class="modal-dialog vertical-align-center">
        <div class="modal-dialog">
          <div class="modal-content" style="margin-left: auto;margin-right: auto;">
            <div class="modal-body">
              <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">×</span><span class="sr-only">Close</span></button> <img src="" class="imagepreview"> </div>
          </div>
        </div>
      </div>
    </div>
  </div>



</body></html>